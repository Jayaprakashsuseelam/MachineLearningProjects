{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T05:26:04.247674Z",
     "start_time": "2024-10-31T05:26:04.242169Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 8.844844403089352e-232\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Example reference (true translation) and hypothesis (model-generated translation)\n",
    "reference = ['It', 'is', 'a', 'guide', 'to', 'action', 'that', 'ensures', 'that', 'the', 'military', 'will', 'forever', 'heed', 'Party', 'commands']\n",
    "hypothesis = ['It', 'is', 'a', 'guide', 'to', 'action', 'which', 'ensures', 'that', 'the', 'military', 'always', 'obeys', 'the', 'commands', 'of', 'the', 'party']\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = sentence_bleu(reference, hypothesis)\n",
    "print(\"BLEU Score:\", bleu_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f634676af4359add",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T05:39:08.827465Z",
     "start_time": "2024-10-31T05:38:54.242326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: nltk in c:\\python312\\lib\\site-packages (3.9.1)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\python312\\lib\\site-packages (from torch) (4.11.0)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jayap\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.3)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from torch) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: click in c:\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python312\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\python312\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\jayap\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jayap\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (2.1.4)\n",
      "Downloading torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "   ---------------------------------------- 0.0/203.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 4.2/203.0 MB 25.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 9.7/203.0 MB 26.3 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 16.3/203.0 MB 28.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 22.8/203.0 MB 29.5 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 31.5/203.0 MB 31.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 39.3/203.0 MB 32.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 45.9/203.0 MB 33.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 55.6/203.0 MB 35.1 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 62.1/203.0 MB 34.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 70.3/203.0 MB 35.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 79.4/203.0 MB 35.9 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 87.0/203.0 MB 35.8 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 94.6/203.0 MB 35.7 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 101.7/203.0 MB 35.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 108.3/203.0 MB 35.5 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 114.3/203.0 MB 35.1 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 122.7/203.0 MB 35.5 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 130.5/203.0 MB 35.6 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 141.0/203.0 MB 36.5 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 151.0/203.0 MB 37.0 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 160.2/203.0 MB 37.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 169.6/203.0 MB 37.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 178.0/203.0 MB 37.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 185.1/203.0 MB 37.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 193.7/203.0 MB 37.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 38.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 38.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 38.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 38.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 203.0/203.0 MB 33.5 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.2/6.2 MB 31.5 MB/s eta 0:00:00\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 47.1 MB/s eta 0:00:00\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Python312\\\\share\\\\man'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Tsk 2\n",
    "# Install necessary libraries\n",
    "!pip install torch nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4f69613322c8780",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T06:01:11.293501Z",
     "start_time": "2024-10-31T06:01:11.277317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output without Attention: tensor([[ 0.0862, -0.1857,  0.0156,  0.2860, -0.1255,  0.0380,  0.0161, -0.1708,\n",
      "          0.0929, -0.0346],\n",
      "        [ 0.0713,  0.0166,  0.0031,  0.3054,  0.1172,  0.0343, -0.1108, -0.1655,\n",
      "          0.2278,  0.1083]], grad_fn=<AddmmBackward0>)\n",
      "Output with Attention: tensor([[ 0.1566, -0.1179, -0.0040, -0.0268, -0.2741, -0.2624, -0.2214, -0.1972,\n",
      "         -0.0754,  0.0650],\n",
      "        [ 0.1633, -0.0942, -0.0743,  0.0351, -0.2487, -0.0896, -0.0737, -0.0470,\n",
      "         -0.0199, -0.0593]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the Encoder class\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "        self.rnn = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return outputs, (hidden, cell)\n",
    "\n",
    "# Define the Decoder without Attention\n",
    "class DecoderNoAttention(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, hidden_dim)\n",
    "        self.rnn = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, input, hidden, cell):\n",
    "        embedded = self.embedding(input).unsqueeze(1)  # embedded: [batch_size, 1, hidden_dim]\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc(output.squeeze(1))  # prediction: [batch_size, output_dim]\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "# Define the Attention Mechanism\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_dim))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        hidden = hidden.expand(encoder_outputs.size(0), encoder_outputs.size(1), -1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attn_weights = torch.sum(self.v * energy, dim=2)\n",
    "        return torch.softmax(attn_weights, dim=1)  # attn_weights: [batch_size, src_len]\n",
    "\n",
    "# Define the Decoder with Attention\n",
    "class DecoderWithAttention(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, attention):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, hidden_dim)\n",
    "        self.rnn = nn.LSTM(hidden_dim * 2, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.attention = attention\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        # input: [batch_size]\n",
    "        embedded = self.embedding(input).unsqueeze(1)  # embedded: [batch_size, 1, hidden_dim]\n",
    "        \n",
    "        attn_weights = self.attention(hidden[-1].unsqueeze(1), encoder_outputs)  # [batch_size, src_len]\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs).squeeze(1)  # context: [batch_size, hidden_dim]\n",
    "        \n",
    "        rnn_input = torch.cat((embedded.squeeze(1), context), dim=1).unsqueeze(1)  # rnn_input: [batch_size, 1, hidden_dim * 2]\n",
    "        output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        \n",
    "        prediction = self.fc(torch.cat((output.squeeze(1), context), dim=1))  # prediction: [batch_size, output_dim]\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = 10  # Vocabulary size of source language\n",
    "output_dim = 10  # Vocabulary size of target language\n",
    "hidden_dim = 16  # Hidden dimension for encoder and decoder\n",
    "batch_size = 2\n",
    "src_len = 5  # Length of the source sentence\n",
    "trg_len = 5  # Length of the target sentence\n",
    "\n",
    "# Instantiate models\n",
    "encoder = Encoder(input_dim, hidden_dim)\n",
    "attention = Attention(hidden_dim)\n",
    "decoder_no_attention = DecoderNoAttention(output_dim, hidden_dim)\n",
    "decoder_with_attention = DecoderWithAttention(output_dim, hidden_dim, attention)\n",
    "\n",
    "# Sample data\n",
    "src = torch.randint(0, input_dim, (batch_size, src_len))  # Randomly generated source batch\n",
    "trg = torch.randint(0, output_dim, (batch_size, trg_len))  # Randomly generated target batch\n",
    "\n",
    "# Forward pass through Encoder\n",
    "encoder_outputs, (hidden, cell) = encoder(src)\n",
    "\n",
    "# Forward pass through Decoder without Attention\n",
    "output_no_attention, hidden, cell = decoder_no_attention(trg[:, 0], hidden, cell)\n",
    "print(\"Output without Attention:\", output_no_attention)\n",
    "\n",
    "# Forward pass through Decoder with Attention\n",
    "output_with_attention, hidden, cell = decoder_with_attention(trg[:, 0], hidden, cell, encoder_outputs)\n",
    "print(\"Output with Attention:\", output_with_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c35ce1d99b4d16e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T08:05:28.030092Z",
     "start_time": "2024-10-31T08:05:28.013141Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Sentence-pairs-in-English-Hindi-2024-10-19.tsv'\n",
    "data = pd.read_csv(file_path, delimiter='\\t', names=['english', 'hindi'])\n",
    "\n",
    "# Ensure all text is of type str and handle missing values\n",
    "data['english'] = data['english'].fillna('').astype(str)\n",
    "data['hindi'] = data['hindi'].fillna('').astype(str)\n",
    "\n",
    "# Re-run the tokenizer on the cleaned dataset\n",
    "english_tokenizer = Tokenizer(filters='')\n",
    "hindi_tokenizer = Tokenizer(filters='')\n",
    "\n",
    "english_tokenizer.fit_on_texts(data['english'])\n",
    "hindi_tokenizer.fit_on_texts(data['hindi'])\n",
    "\n",
    "# Convert texts to sequences\n",
    "input_sequences = english_tokenizer.texts_to_sequences(data['english'])\n",
    "target_sequences = hindi_tokenizer.texts_to_sequences(data['hindi'])\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "max_length_input = max(len(seq) for seq in input_sequences)\n",
    "max_length_target = max(len(seq) for seq in target_sequences)\n",
    "\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_length_input, padding='post')\n",
    "target_sequences = pad_sequences(target_sequences, maxlen=max_length_target, padding='post')\n",
    "\n",
    "# Prepare input and output data for training\n",
    "target_sequences_input = target_sequences[:, :-1]\n",
    "target_sequences_output = target_sequences[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "294434e55dae7c48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T08:05:30.148452Z",
     "start_time": "2024-10-31T08:05:30.126041Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(enc_units, return_sequences=True, return_state=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x)\n",
    "        return output, state\n",
    "\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(dec_units, return_sequences=True, return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.attention = BahdanauAttention(dec_units)\n",
    "\n",
    "    def call(self, x, enc_output, hidden):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.gru(x)\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights\n",
    "encoder = Encoder(len(english_tokenizer.word_index) + 1, 256, 512)\n",
    "decoder = Decoder(len(hindi_tokenizer.word_index) + 1, 256, 512)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.not_equal(real, 0)\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    " \n",
    "@tf.function\n",
    "def train_step(input_seq, target_seq_in, target_seq_out, encoder, decoder):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(input_seq)\n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        for t in range(target_seq_out.shape[1]):\n",
    "            dec_input = tf.expand_dims(target_seq_in[:, t], 1)\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, enc_output, dec_hidden)\n",
    "            \n",
    "            # Squeeze to match target shape\n",
    "            predictions = tf.squeeze(predictions, axis=1)\n",
    "            \n",
    "            # Calculate loss without using .numpy()\n",
    "            loss += loss_function(target_seq_out[:, t], predictions)\n",
    "\n",
    "    batch_loss = loss / int(target_seq_out.shape[1])\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ef5659a3d896bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T08:06:38.440542Z",
     "start_time": "2024-10-31T08:05:33.927838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.661006927490234\n",
      "Epoch 2, Loss: 4.750603675842285\n",
      "Epoch 3, Loss: 3.4511454105377197\n",
      "Epoch 4, Loss: 3.3393969535827637\n",
      "Epoch 5, Loss: 3.2187347412109375\n",
      "Epoch 6, Loss: 3.1251773834228516\n",
      "Epoch 7, Loss: 3.026987075805664\n",
      "Epoch 8, Loss: 2.8859214782714844\n",
      "Epoch 9, Loss: 2.7351441383361816\n",
      "Epoch 10, Loss: 2.628237009048462\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "batch_size = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((input_sequences, target_sequences))\n",
    "train_dataset = train_dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for batch, (input_seq, target_seq) in enumerate(train_dataset):\n",
    "        target_seq_in = target_seq[:, :-1]\n",
    "        target_seq_out = target_seq[:, 1:]\n",
    "        \n",
    "        # Call the train_step function without using .numpy() here\n",
    "        batch_loss = train_step(input_seq, target_seq_in, target_seq_out, encoder, decoder)\n",
    "        total_loss += batch_loss  # No need for .numpy() here\n",
    "\n",
    "    # Convert the total loss to a numpy value only when printing outside @tf.function\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
